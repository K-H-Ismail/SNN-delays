{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===> Device = cuda\n"
     ]
    }
   ],
   "source": [
    "from datasets import SHD_dataloaders\n",
    "from config import Config\n",
    "from ann import ANN\n",
    "from snn_delays import SnnDelays\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n===> Device = {device}\")\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [../Datasets/extract] for saving extracted files already exists.\n",
      "SpikingJelly will not check the data integrity of extracted files.\n",
      "If extracted files are not integrated, please delete [../Datasets/extract] manually, then SpikingJelly will re-extract files from [../Datasets/download].\n",
      "The directory [../Datasets/duration_10] already exists.\n",
      "The directory [../Datasets/extract] for saving extracted files already exists.\n",
      "SpikingJelly will not check the data integrity of extracted files.\n",
      "If extracted files are not integrated, please delete [../Datasets/extract] manually, then SpikingJelly will re-extract files from [../Datasets/download].\n",
      "The directory [../Datasets/duration_10] already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/thanatos/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthvnvtos\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/thanatos/PhD/snn-delays/SNN-delays/wandb/run-20230416_204839-ck7pm1rv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thvnvtos/Models%20comparison/runs/ck7pm1rv' target=\"_blank\">Baseline(Pre-train)||seed=0||snn_delays||shd||10ms||bins=10</a></strong> to <a href='https://wandb.ai/thvnvtos/Models%20comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thvnvtos/Models%20comparison' target=\"_blank\">https://wandb.ai/thvnvtos/Models%20comparison</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thvnvtos/Models%20comparison/runs/ck7pm1rv' target=\"_blank\">https://wandb.ai/thvnvtos/Models%20comparison/runs/ck7pm1rv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch 0 : \n",
      "Loss Train = 3.692  |  Best Acc Train = 7.02% \n",
      "Loss Test = 2.881  |  Best Acc Test = 15.60%\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader = SHD_dataloaders(config)\n",
    "model = SnnDelays(config).to(device)\n",
    "\n",
    "model.train_model(train_loader, valid_loader, device)\n",
    "\n",
    "PATH = \"model.pt\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [../Datasets/extract] for saving extracted files already exists.\n",
      "SpikingJelly will not check the data integrity of extracted files.\n",
      "If extracted files are not integrated, please delete [../Datasets/extract] manually, then SpikingJelly will re-extract files from [../Datasets/download].\n",
      "The directory [../Datasets/duration_10] already exists.\n",
      "The directory [../Datasets/extract] for saving extracted files already exists.\n",
      "SpikingJelly will not check the data integrity of extracted files.\n",
      "If extracted files are not integrated, please delete [../Datasets/extract] manually, then SpikingJelly will re-extract files from [../Datasets/download].\n",
      "The directory [../Datasets/duration_10] already exists.\n",
      "tensor(-1., device='cuda:0')\n",
      "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4164e-07, -6.7569e-01,\n",
      "        -2.4164e-07,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(1.0000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "config.DCLSversion = 'v2'\n",
    "config.model_type = 'snn_delays_lr0'\n",
    "config.wandb_run_name = config.wandb_run_name.replace('(Pre-train)', '(Fine-tune2)')\n",
    "config.wandb_group_name = config.wandb_group_name.replace('(Pre-train)', '(Fine-tune)')\n",
    "\n",
    "#config.lr_w = 1e-4\n",
    "#config.max_lr_w = 5 * config.lr_w\n",
    "\n",
    "config.dropout_p = 0.25\n",
    "config.stateful_synapse_learnable = True\n",
    "config.spiking_neuron_type = 'plif'\n",
    "config.epochs = 70\n",
    "\n",
    "\n",
    "train_loader, valid_loader = SHD_dataloaders(config)\n",
    "model_d = SnnDelays(config).to(device)\n",
    "\n",
    "PATH = \"model.pt\"\n",
    "model_d.load_state_dict(torch.load(PATH), strict=False)\n",
    "\n",
    "model_d.round_pos()\n",
    "\n",
    "w = model_d.blocks[0][0][0].weight\n",
    "p = model_d.blocks[0][0][0].P\n",
    "sig = model_d.blocks[0][0][0].SIG\n",
    "\n",
    "kernel = model_d.blocks[0][0][0].GCK.forward(w, p , sig)\n",
    "print(p[0,1,0,0])\n",
    "print(kernel[1,0])\n",
    "\n",
    "print(sig[0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/thanatos/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/thanatos/PhD/snn-delays/SNN-delays/wandb/run-20230416_202038-j1b06431</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thvnvtos/Models%20comparison/runs/j1b06431' target=\"_blank\">Baseline(Fine-tune)||seed=0||snn_delays||shd||10ms||bins=10</a></strong> to <a href='https://wandb.ai/thvnvtos/Models%20comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thvnvtos/Models%20comparison' target=\"_blank\">https://wandb.ai/thvnvtos/Models%20comparison</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thvnvtos/Models%20comparison/runs/j1b06431' target=\"_blank\">https://wandb.ai/thvnvtos/Models%20comparison/runs/j1b06431</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch 0 : \n",
      "Loss Train = 0.295  |  Best Acc Train = 90.08% \n",
      "Loss Test = 0.186  |  Best Acc Test = 93.78%\n",
      "=====> Epoch 1 : \n",
      "Loss Train = 0.255  |  Best Acc Train = 91.49% \n",
      "Loss Test = 0.213  |  Best Acc Test = 93.78%\n",
      "=====> Epoch 2 : \n",
      "Loss Train = 0.230  |  Best Acc Train = 92.50% \n",
      "Loss Test = 0.207  |  Best Acc Test = 93.78%\n",
      "=====> Epoch 3 : \n",
      "Loss Train = 0.217  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.207  |  Best Acc Test = 93.78%\n",
      "=====> Epoch 4 : \n",
      "Loss Train = 0.209  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.192  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 5 : \n",
      "Loss Train = 0.221  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.248  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 6 : \n",
      "Loss Train = 0.271  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.273  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 7 : \n",
      "Loss Train = 0.327  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.299  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 8 : \n",
      "Loss Train = 0.358  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.231  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 9 : \n",
      "Loss Train = 0.409  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.287  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 10 : \n",
      "Loss Train = 0.430  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.197  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 11 : \n",
      "Loss Train = 0.422  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.277  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 12 : \n",
      "Loss Train = 0.455  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.391  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 13 : \n",
      "Loss Train = 0.473  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.561  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 14 : \n",
      "Loss Train = 0.426  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.430  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 15 : \n",
      "Loss Train = 0.425  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.333  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 16 : \n",
      "Loss Train = 0.351  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.255  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 17 : \n",
      "Loss Train = 0.391  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.331  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 18 : \n",
      "Loss Train = 0.322  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.271  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 19 : \n",
      "Loss Train = 0.322  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.275  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 20 : \n",
      "Loss Train = 0.327  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.281  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 21 : \n",
      "Loss Train = 0.306  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.291  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 22 : \n",
      "Loss Train = 0.266  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.370  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 23 : \n",
      "Loss Train = 0.272  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.329  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 24 : \n",
      "Loss Train = 0.236  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.319  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 25 : \n",
      "Loss Train = 0.235  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.280  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 26 : \n",
      "Loss Train = 0.217  |  Best Acc Train = 92.79% \n",
      "Loss Test = 0.187  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 27 : \n",
      "Loss Train = 0.209  |  Best Acc Train = 93.01% \n",
      "Loss Test = 0.293  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 28 : \n",
      "Loss Train = 0.215  |  Best Acc Train = 93.01% \n",
      "Loss Test = 0.256  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 29 : \n",
      "Loss Train = 0.214  |  Best Acc Train = 93.05% \n",
      "Loss Test = 0.201  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 30 : \n",
      "Loss Train = 0.213  |  Best Acc Train = 93.05% \n",
      "Loss Test = 0.266  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 31 : \n",
      "Loss Train = 0.202  |  Best Acc Train = 93.05% \n",
      "Loss Test = 0.227  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 32 : \n",
      "Loss Train = 0.179  |  Best Acc Train = 93.75% \n",
      "Loss Test = 0.215  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 33 : \n",
      "Loss Train = 0.164  |  Best Acc Train = 94.51% \n",
      "Loss Test = 0.213  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 34 : \n",
      "Loss Train = 0.160  |  Best Acc Train = 94.51% \n",
      "Loss Test = 0.204  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 35 : \n",
      "Loss Train = 0.137  |  Best Acc Train = 95.24% \n",
      "Loss Test = 0.263  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 36 : \n",
      "Loss Train = 0.140  |  Best Acc Train = 95.24% \n",
      "Loss Test = 0.264  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 37 : \n",
      "Loss Train = 0.127  |  Best Acc Train = 95.47% \n",
      "Loss Test = 0.222  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 38 : \n",
      "Loss Train = 0.132  |  Best Acc Train = 95.47% \n",
      "Loss Test = 0.212  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 39 : \n",
      "Loss Train = 0.105  |  Best Acc Train = 96.30% \n",
      "Loss Test = 0.206  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 40 : \n",
      "Loss Train = 0.105  |  Best Acc Train = 96.30% \n",
      "Loss Test = 0.193  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 41 : \n",
      "Loss Train = 0.113  |  Best Acc Train = 96.44% \n",
      "Loss Test = 0.208  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 42 : \n",
      "Loss Train = 0.107  |  Best Acc Train = 96.44% \n",
      "Loss Test = 0.214  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 43 : \n",
      "Loss Train = 0.109  |  Best Acc Train = 96.44% \n",
      "Loss Test = 0.202  |  Best Acc Test = 93.83%\n",
      "=====> Epoch 44 : \n",
      "Loss Train = 0.101  |  Best Acc Train = 96.49% \n",
      "Loss Test = 0.205  |  Best Acc Test = 94.29%\n",
      "=====> Epoch 45 : \n",
      "Loss Train = 0.106  |  Best Acc Train = 96.49% \n",
      "Loss Test = 0.218  |  Best Acc Test = 94.29%\n",
      "=====> Epoch 46 : \n",
      "Loss Train = 0.098  |  Best Acc Train = 96.49% \n",
      "Loss Test = 0.196  |  Best Acc Test = 94.29%\n",
      "=====> Epoch 47 : \n",
      "Loss Train = 0.097  |  Best Acc Train = 96.69% \n",
      "Loss Test = 0.211  |  Best Acc Test = 94.29%\n",
      "=====> Epoch 48 : \n",
      "Loss Train = 0.085  |  Best Acc Train = 96.91% \n",
      "Loss Test = 0.209  |  Best Acc Test = 94.29%\n",
      "=====> Epoch 49 : \n",
      "Loss Train = 0.104  |  Best Acc Train = 96.91% \n",
      "Loss Test = 0.204  |  Best Acc Test = 94.29%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>acc_test</td><td>█▇█▇▆▆▅▇▇▆▃▁▅▆▅▆▇▆▅▅▇█▆▇▆▇▇▇▆▆▇█████████</td></tr><tr><td>acc_train</td><td>▄▅▅▆▅▄▄▃▂▂▂▁▂▃▂▄▄▄▅▄▅▆▆▆▆▆▆▇▇▇▇▇████████</td></tr><tr><td>loss_test</td><td>▁▂▁▁▂▃▃▂▁▃▅█▄▂▄▃▃▃▄▄▃▁▃▂▃▂▂▂▂▂▂▁▁▁▂▁▂▁▁▁</td></tr><tr><td>loss_train</td><td>▅▄▃▃▃▄▅▆▇▇██▇▆▆▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_pos</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_w</td><td>▁▂▂▃▄▅▅▆▇███████▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>sigma</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tau_m_0</td><td>▁▁▁▁▁▁▁▂▃▃▃▃▄▄▅▅▆▆▆▅▆▆▆▇▆▇▇▇▇▇▇█████████</td></tr><tr><td>tau_m_1</td><td>▁▁▁▁▂▂▃▅▆▆▆▇▆██▇▇▆▅▆▆▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>tau_m_2</td><td>▁▁▁▂▂▃▄▆█▆▆▇▇█▇▆▆▆▅▅▅▇▇▇▅▆▇▇▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>tau_s_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tau_s_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tau_s_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>w_0</td><td>▁▁▁▁▁▁▂▂▃▃▄▄▅▅▆▆▆▇▇▇▇▇▇█████████████████</td></tr><tr><td>w_1</td><td>▁▁▁▁▁▁▂▂▃▄▄▅▅▆▆▆▇▇▇▇▇▇██████████████████</td></tr><tr><td>w_2</td><td>▁▁▁▁▁▂▂▂▃▄▄▅▅▆▆▆▇▇▇▇▇▇██████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>49</td></tr><tr><td>acc_test</td><td>0.93383</td></tr><tr><td>acc_train</td><td>0.96402</td></tr><tr><td>loss_test</td><td>0.20443</td></tr><tr><td>loss_train</td><td>0.10412</td></tr><tr><td>lr_pos</td><td>0.5</td></tr><tr><td>lr_w</td><td>4e-05</td></tr><tr><td>sigma</td><td>1.0</td></tr><tr><td>tau_m_0</td><td>23.58317</td></tr><tr><td>tau_m_1</td><td>34.79958</td></tr><tr><td>tau_m_2</td><td>24.03047</td></tr><tr><td>tau_s_0</td><td>15.0</td></tr><tr><td>tau_s_1</td><td>15.0</td></tr><tr><td>tau_s_2</td><td>0</td></tr><tr><td>w_0</td><td>0.73072</td></tr><tr><td>w_1</td><td>0.55312</td></tr><tr><td>w_2</td><td>0.56652</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Baseline(Fine-tune)||seed=0||snn_delays||shd||10ms||bins=10</strong> at: <a href='https://wandb.ai/thvnvtos/Models%20comparison/runs/j1b06431' target=\"_blank\">https://wandb.ai/thvnvtos/Models%20comparison/runs/j1b06431</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230416_202038-j1b06431/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_d.train_model(train_loader, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7., device='cuda:0')\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -2.5519,  0.0000,  0.0000,  0.0000], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "w = model_d.blocks[0][0][0].weight\n",
    "p = model_d.blocks[0][0][0].P\n",
    "sig = model_d.blocks[0][0][0].SIG\n",
    "\n",
    "kernel = model_d.blocks[0][0][0].GCK.forward(w, p , sig)\n",
    "print(p[0,2,0,0])\n",
    "print(kernel[2,0])\n",
    "\n",
    "print(sig[0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn-delays",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
