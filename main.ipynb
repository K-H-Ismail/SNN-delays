{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===> Device = cuda\n"
     ]
    }
   ],
   "source": [
    "from datasets import SHD_dataloaders\n",
    "from config import Config\n",
    "from ann import ANN\n",
    "from snn_delays import SnnDelays\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n===> Device = {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [../Datasets/extract] for saving extracted files already exists.\n",
      "SpikingJelly will not check the data integrity of extracted files.\n",
      "If extracted files are not integrated, please delete [../Datasets/extract] manually, then SpikingJelly will re-extract files from [../Datasets/download].\n",
      "The directory [../Datasets/duration_20] already exists.\n",
      "The directory [../Datasets/extract] for saving extracted files already exists.\n",
      "SpikingJelly will not check the data integrity of extracted files.\n",
      "If extracted files are not integrated, please delete [../Datasets/extract] manually, then SpikingJelly will re-extract files from [../Datasets/download].\n",
      "The directory [../Datasets/duration_20] already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthvnvtos\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/thanatos/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/thanatos/PhD/snn-delays/SNN-delays/wandb/run-20230415_195723-qje2wkwm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thvnvtos/SHD-BestACC/runs/qje2wkwm' target=\"_blank\">Baseline Tests||Fine-tine Test||shd||snn_delays||sum||MaxDelay=13||neuron=lif||seed=0</a></strong> to <a href='https://wandb.ai/thvnvtos/SHD-BestACC' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thvnvtos/SHD-BestACC' target=\"_blank\">https://wandb.ai/thvnvtos/SHD-BestACC</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thvnvtos/SHD-BestACC/runs/qje2wkwm' target=\"_blank\">https://wandb.ai/thvnvtos/SHD-BestACC/runs/qje2wkwm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch 0 : \n",
      "Loss Train = 2.726  |  Best Acc Train = 19.69% \n",
      "Loss Test = 1.903  |  Best Acc Test = 46.51%\n",
      "=====> Epoch 1 : \n",
      "Loss Train = 1.752  |  Best Acc Train = 50.27% \n",
      "Loss Test = 1.105  |  Best Acc Test = 71.30%\n",
      "=====> Epoch 2 : \n",
      "Loss Train = 1.094  |  Best Acc Train = 69.06% \n",
      "Loss Test = 0.677  |  Best Acc Test = 79.66%\n",
      "=====> Epoch 3 : \n",
      "Loss Train = 0.688  |  Best Acc Train = 79.91% \n",
      "Loss Test = 0.615  |  Best Acc Test = 79.86%\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "train_loader, valid_loader = SHD_dataloaders(config)\n",
    "model = SnnDelays(config).to(device)\n",
    "\n",
    "model.train_model(train_loader, valid_loader, device)\n",
    "\n",
    "PATH = \"model.pt\"\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [../Datasets/extract] for saving extracted files already exists.\n",
      "SpikingJelly will not check the data integrity of extracted files.\n",
      "If extracted files are not integrated, please delete [../Datasets/extract] manually, then SpikingJelly will re-extract files from [../Datasets/download].\n",
      "The directory [../Datasets/duration_20] already exists.\n",
      "The directory [../Datasets/extract] for saving extracted files already exists.\n",
      "SpikingJelly will not check the data integrity of extracted files.\n",
      "If extracted files are not integrated, please delete [../Datasets/extract] manually, then SpikingJelly will re-extract files from [../Datasets/download].\n",
      "The directory [../Datasets/duration_20] already exists.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config()\n",
    "\n",
    "config.DCLSversion = 'v2'\n",
    "config.model_type = 'snn_delays_lr0'\n",
    "config.lr_w = 5e-4\n",
    "\n",
    "train_loader, valid_loader = SHD_dataloaders(config)\n",
    "model_d = SnnDelays(config).to(device)\n",
    "\n",
    "PATH = \"model.pt\"\n",
    "model_d.load_state_dict(torch.load(PATH), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [../Datasets/extract] for saving extracted files already exists.\n",
      "SpikingJelly will not check the data integrity of extracted files.\n",
      "If extracted files are not integrated, please delete [../Datasets/extract] manually, then SpikingJelly will re-extract files from [../Datasets/download].\n",
      "The directory [../Datasets/duration_20] already exists.\n",
      "The directory [../Datasets/extract] for saving extracted files already exists.\n",
      "SpikingJelly will not check the data integrity of extracted files.\n",
      "If extracted files are not integrated, please delete [../Datasets/extract] manually, then SpikingJelly will re-extract files from [../Datasets/download].\n",
      "The directory [../Datasets/duration_20] already exists.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDcls1d(\n",
      "  70, 128, kernel_count=1 (previous kernel_size), stride=(1,), version=v2, dilated_kernel_size=(13,) (learnable), bias=False\n",
      "  (GCK): GConstructKernel1d()\n",
      ")\n",
      "GDcls1d(\n",
      "  128, 128, kernel_count=1 (previous kernel_size), stride=(1,), version=v2, dilated_kernel_size=(13,) (learnable), bias=False\n",
      "  (GCK): GConstructKernel1d()\n",
      ")\n",
      "GDcls1d(\n",
      "  128, 20, kernel_count=1 (previous kernel_size), stride=(1,), version=v2, dilated_kernel_size=(13,) (learnable), bias=False\n",
      "  (GCK): GConstructKernel1d()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(len(model_d.blocks)):\n",
    "        print(model_d.blocks[i][0][0])\n",
    "        model_d.blocks[i][0][0].P.round_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch 0 : \n",
      "Loss Train = 0.540  |  Best Acc Train = 85.31% \n",
      "Loss Test = 0.483  |  Best Acc Test = 84.56%\n",
      "=====> Epoch 1 : \n",
      "Loss Train = 0.455  |  Best Acc Train = 86.79% \n",
      "Loss Test = 0.437  |  Best Acc Test = 85.13%\n",
      "=====> Epoch 2 : \n",
      "Loss Train = 0.366  |  Best Acc Train = 88.92% \n",
      "Loss Test = 0.402  |  Best Acc Test = 85.62%\n",
      "=====> Epoch 3 : \n",
      "Loss Train = 0.308  |  Best Acc Train = 90.83% \n",
      "Loss Test = 0.358  |  Best Acc Test = 86.60%\n",
      "=====> Epoch 4 : \n",
      "Loss Train = 0.298  |  Best Acc Train = 91.19% \n",
      "Loss Test = 0.352  |  Best Acc Test = 87.07%\n"
     ]
    }
   ],
   "source": [
    "model_d.train_model(train_loader, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1., device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1908, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = model_d.blocks[0][0][0].weight\n",
    "p = model_d.blocks[0][0][0].P.detach()\n",
    "sig = model_d.blocks[0][0][0].SIG\n",
    "\n",
    "kernel = model_d.blocks[0][0][0].GCK.forward(w, p , sig)\n",
    "print(p[0,2,0,0])\n",
    "kernel[2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          ...,\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000]],\n",
       "\n",
       "         [[0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          ...,\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000]],\n",
       "\n",
       "         [[0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          ...,\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          ...,\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000]],\n",
       "\n",
       "         [[0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          ...,\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000]],\n",
       "\n",
       "         [[0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          ...,\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000]]]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn-delays",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
