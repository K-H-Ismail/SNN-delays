{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===> Device = cuda\n"
     ]
    }
   ],
   "source": [
    "from datasets import SHD_dataloaders, SSC_dataloaders\n",
    "from config import Config\n",
    "from ann import ANN\n",
    "from snn_delays import SnnDelays\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n===> Device = {device}\")\n",
    "\n",
    "config = Config()\n",
    "\n",
    "model = SnnDelays(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthvnvtos\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/thanatos/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/thanatos/PhD/snn-delays/SNN-delays/wandb/run-20230420_105558-cmm29dew</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thvnvtos/Models%20comparison/runs/cmm29dew' target=\"_blank\">(Pre-train)Testing_code||seed=0||snn_delays||shd||20ms||bins=10</a></strong> to <a href='https://wandb.ai/thvnvtos/Models%20comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thvnvtos/Models%20comparison' target=\"_blank\">https://wandb.ai/thvnvtos/Models%20comparison</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thvnvtos/Models%20comparison/runs/cmm29dew' target=\"_blank\">https://wandb.ai/thvnvtos/Models%20comparison/runs/cmm29dew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch 0 : \n",
      "Loss Train = 2.914  |  Best Acc Train = 15.31% \n",
      "Loss Test = 2.254  |  Best Acc Test = 28.99%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mtrain_model(train_loader, valid_loader, device)\n",
      "File \u001b[0;32m~/PhD/snn-delays/SNN-delays/model.py:174\u001b[0m, in \u001b[0;36mModel.train_model\u001b[0;34m(self, train_loader, valid_loader, device)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39m#last element in the tuple corresponds to the collate_fn return\u001b[39;00m\n\u001b[1;32m    173\u001b[0m loss_batch, metric_batch \u001b[39m=\u001b[39m [], []\n\u001b[0;32m--> 174\u001b[0m \u001b[39mfor\u001b[39;00m i, (x, y, _) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m    175\u001b[0m     \u001b[39m# x for shd and ssc is: (batch, neurons, time)\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    177\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/snn-delays/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/snn-delays/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/snn-delays/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/snn-delays/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/snn-delays/lib/python3.10/site-packages/spikingjelly-0.0.0.0.14-py3.10.egg/spikingjelly/datasets/shd.py:413\u001b[0m, in \u001b[0;36mSpikingHeidelbergDigits.__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[39mreturn\u001b[39;00m events, label\n\u001b[1;32m    412\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 413\u001b[0m     frames \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mframes_path[i], allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m'\u001b[39;49m\u001b[39mframes\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m    414\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframes_label[i]\n\u001b[1;32m    416\u001b[0m     binned_len \u001b[39m=\u001b[39m frames\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_bins\n",
      "File \u001b[0;32m~/anaconda3/envs/snn-delays/lib/python3.10/site-packages/numpy/lib/npyio.py:253\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mif\u001b[39;00m magic \u001b[39m==\u001b[39m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mMAGIC_PREFIX:\n\u001b[1;32m    252\u001b[0m     \u001b[39mbytes\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzip\u001b[39m.\u001b[39mopen(key)\n\u001b[0;32m--> 253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(\u001b[39mbytes\u001b[39;49m,\n\u001b[1;32m    254\u001b[0m                              allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mallow_pickle,\n\u001b[1;32m    255\u001b[0m                              pickle_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpickle_kwargs,\n\u001b[1;32m    256\u001b[0m                              max_header_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_header_size)\n\u001b[1;32m    257\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzip\u001b[39m.\u001b[39mread(key)\n",
      "File \u001b[0;32m~/anaconda3/envs/snn-delays/lib/python3.10/site-packages/numpy/lib/format.py:765\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    763\u001b[0m version \u001b[39m=\u001b[39m read_magic(fp)\n\u001b[1;32m    764\u001b[0m _check_version(version)\n\u001b[0;32m--> 765\u001b[0m shape, fortran_order, dtype \u001b[39m=\u001b[39m _read_array_header(\n\u001b[1;32m    766\u001b[0m         fp, version, max_header_size\u001b[39m=\u001b[39;49mmax_header_size)\n\u001b[1;32m    767\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shape) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    768\u001b[0m     count \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/snn-delays/lib/python3.10/site-packages/numpy/lib/format.py:616\u001b[0m, in \u001b[0;36m_read_array_header\u001b[0;34m(fp, version, max_header_size)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[39m# The header is a pretty-printed string representation of a literal\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[39m# Python dictionary with trailing newlines padded to a ARRAY_ALIGN byte\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[39m# boundary. The keys are strings.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39m# Versions (2, 0) and (1, 0) could have been created by a Python 2\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[39m# implementation before header filtering was implemented.\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[39mif\u001b[39;00m version \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m):\n\u001b[0;32m--> 616\u001b[0m     header \u001b[39m=\u001b[39m _filter_header(header)\n\u001b[1;32m    617\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     d \u001b[39m=\u001b[39m safe_eval(header)\n",
      "File \u001b[0;32m~/anaconda3/envs/snn-delays/lib/python3.10/site-packages/numpy/lib/format.py:569\u001b[0m, in \u001b[0;36m_filter_header\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    567\u001b[0m tokens \u001b[39m=\u001b[39m []\n\u001b[1;32m    568\u001b[0m last_token_was_number \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokenize\u001b[39m.\u001b[39mgenerate_tokens(StringIO(s)\u001b[39m.\u001b[39mreadline):\n\u001b[1;32m    570\u001b[0m     token_type \u001b[39m=\u001b[39m token[\u001b[39m0\u001b[39m]\n\u001b[1;32m    571\u001b[0m     token_string \u001b[39m=\u001b[39m token[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/snn-delays/lib/python3.10/tokenize.py:527\u001b[0m, in \u001b[0;36m_tokenize\u001b[0;34m(readline, encoding)\u001b[0m\n\u001b[1;32m    524\u001b[0m     continued \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    526\u001b[0m \u001b[39mwhile\u001b[39;00m pos \u001b[39m<\u001b[39m \u001b[39mmax\u001b[39m:\n\u001b[0;32m--> 527\u001b[0m     pseudomatch \u001b[39m=\u001b[39m _compile(PseudoToken)\u001b[39m.\u001b[39;49mmatch(line, pos)\n\u001b[1;32m    528\u001b[0m     \u001b[39mif\u001b[39;00m pseudomatch:                                \u001b[39m# scan for tokens\u001b[39;00m\n\u001b[1;32m    529\u001b[0m         start, end \u001b[39m=\u001b[39m pseudomatch\u001b[39m.\u001b[39mspan(\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader = SHD_dataloaders(config)\n",
    "model.train_model(train_loader, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [../Datasets/SHD/extract] for saving extracted files already exists.\n",
      "SpikingJelly will not check the data integrity of extracted files.\n",
      "If extracted files are not integrated, please delete [../Datasets/SHD/extract] manually, then SpikingJelly will re-extract files from [../Datasets/SHD/download].\n",
      "The directory [../Datasets/SHD/duration_20] already exists.\n",
      "The directory [../Datasets/SHD/extract] for saving extracted files already exists.\n",
      "SpikingJelly will not check the data integrity of extracted files.\n",
      "If extracted files are not integrated, please delete [../Datasets/SHD/extract] manually, then SpikingJelly will re-extract files from [../Datasets/SHD/download].\n",
      "The directory [../Datasets/SHD/duration_20] already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthvnvtos\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/thanatos/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/thanatos/PhD/snn-delays/SNN-delays/wandb/run-20230420_110225-h2ncqw41</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thvnvtos/Models%20comparison/runs/h2ncqw41' target=\"_blank\">(Fine-tune_lr=0.0001->0.0002_dropout=0.25_plif_SS=True)Testing_code||seed=0||snn_delays||shd||20ms||bins=10</a></strong> to <a href='https://wandb.ai/thvnvtos/Models%20comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thvnvtos/Models%20comparison' target=\"_blank\">https://wandb.ai/thvnvtos/Models%20comparison</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thvnvtos/Models%20comparison/runs/h2ncqw41' target=\"_blank\">https://wandb.ai/thvnvtos/Models%20comparison/runs/h2ncqw41</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch 0 : \n",
      "Loss Train = 0.197  |  Best Acc Train = 95.37% \n",
      "Loss Test = 0.260  |  Best Acc Test = 91.24%\n",
      "=====> Epoch 1 : \n",
      "Loss Train = 0.181  |  Best Acc Train = 95.83% \n",
      "Loss Test = 0.257  |  Best Acc Test = 91.76%\n",
      "=====> Epoch 2 : \n",
      "Loss Train = 0.157  |  Best Acc Train = 96.52% \n",
      "Loss Test = 0.241  |  Best Acc Test = 92.25%\n",
      "=====> Epoch 3 : \n",
      "Loss Train = 0.143  |  Best Acc Train = 96.62% \n",
      "Loss Test = 0.240  |  Best Acc Test = 92.92%\n",
      "=====> Epoch 4 : \n",
      "Loss Train = 0.123  |  Best Acc Train = 97.14% \n",
      "Loss Test = 0.237  |  Best Acc Test = 92.92%\n",
      "=====> Epoch 5 : \n",
      "Loss Train = 0.115  |  Best Acc Train = 97.20% \n",
      "Loss Test = 0.236  |  Best Acc Test = 92.92%\n",
      "=====> Epoch 6 : \n",
      "Loss Train = 0.103  |  Best Acc Train = 97.65% \n",
      "Loss Test = 0.237  |  Best Acc Test = 92.92%\n",
      "=====> Epoch 7 : \n",
      "Loss Train = 0.100  |  Best Acc Train = 97.68% \n",
      "Loss Test = 0.237  |  Best Acc Test = 92.92%\n",
      "=====> Epoch 8 : \n",
      "Loss Train = 0.099  |  Best Acc Train = 97.68% \n",
      "Loss Test = 0.236  |  Best Acc Test = 92.92%\n",
      "=====> Epoch 9 : \n",
      "Loss Train = 0.094  |  Best Acc Train = 97.92% \n",
      "Loss Test = 0.229  |  Best Acc Test = 92.92%\n",
      "=====> Epoch 10 : \n",
      "Loss Train = 0.095  |  Best Acc Train = 97.92% \n",
      "Loss Test = 0.231  |  Best Acc Test = 92.92%\n",
      "=====> Epoch 11 : \n",
      "Loss Train = 0.087  |  Best Acc Train = 98.04% \n",
      "Loss Test = 0.228  |  Best Acc Test = 92.92%\n",
      "=====> Epoch 12 : \n",
      "Loss Train = 0.092  |  Best Acc Train = 98.04% \n",
      "Loss Test = 0.226  |  Best Acc Test = 92.92%\n",
      "=====> Epoch 13 : \n",
      "Loss Train = 0.085  |  Best Acc Train = 98.21% \n",
      "Loss Test = 0.225  |  Best Acc Test = 92.92%\n",
      "=====> Epoch 14 : \n",
      "Loss Train = 0.091  |  Best Acc Train = 98.21% \n",
      "Loss Test = 0.232  |  Best Acc Test = 92.92%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>acc_test</td><td>▁▃▅█▃▅▅▆▅▇▇▇▇▇▆</td></tr><tr><td>acc_train</td><td>▁▂▄▄▅▅▇▇▇▇▇█▇██</td></tr><tr><td>loss_test</td><td>█▇▄▄▄▃▃▃▃▂▂▂▁▁▂</td></tr><tr><td>loss_train</td><td>█▇▅▅▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>lr_pos</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_w</td><td>▃▅███▇▆▅▄▃▂▂▁▁▁</td></tr><tr><td>sigma</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tau_m_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tau_m_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tau_m_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tau_s_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tau_s_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tau_s_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>w_0</td><td>▁▁▂▃▄▅▆▇▇██████</td></tr><tr><td>w_1</td><td>▁▁▂▃▅▅▆▇▇▇█████</td></tr><tr><td>w_2</td><td>▁▁▂▃▄▅▆▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>14</td></tr><tr><td>acc_test</td><td>0.92487</td></tr><tr><td>acc_train</td><td>0.9801</td></tr><tr><td>loss_test</td><td>0.23228</td></tr><tr><td>loss_train</td><td>0.09101</td></tr><tr><td>lr_pos</td><td>0.1</td></tr><tr><td>lr_w</td><td>0.0</td></tr><tr><td>sigma</td><td>1.0</td></tr><tr><td>tau_m_0</td><td>20.0</td></tr><tr><td>tau_m_1</td><td>20.0</td></tr><tr><td>tau_m_2</td><td>20.0</td></tr><tr><td>tau_s_0</td><td>30.0</td></tr><tr><td>tau_s_1</td><td>30.0</td></tr><tr><td>tau_s_2</td><td>0</td></tr><tr><td>w_0</td><td>0.16338</td></tr><tr><td>w_1</td><td>0.08222</td></tr><tr><td>w_2</td><td>0.11412</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">(Fine-tune_lr=0.0001->0.0002_dropout=0.25_plif_SS=True)Testing_code||seed=0||snn_delays||shd||20ms||bins=10</strong> at: <a href='https://wandb.ai/thvnvtos/Models%20comparison/runs/h2ncqw41' target=\"_blank\">https://wandb.ai/thvnvtos/Models%20comparison/runs/h2ncqw41</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230420_110225-h2ncqw41/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader, valid_loader = SHD_dataloaders(config)\n",
    "model.fine_tune(train_loader, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0e-04'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [../Datasets/extract] for saving extracted files already exists.\n",
      "SpikingJelly will not check the data integrity of extracted files.\n",
      "If extracted files are not integrated, please delete [../Datasets/extract] manually, then SpikingJelly will re-extract files from [../Datasets/download].\n",
      "The directory [../Datasets/duration_10] already exists.\n",
      "The directory [../Datasets/extract] for saving extracted files already exists.\n",
      "SpikingJelly will not check the data integrity of extracted files.\n",
      "If extracted files are not integrated, please delete [../Datasets/extract] manually, then SpikingJelly will re-extract files from [../Datasets/download].\n",
      "The directory [../Datasets/duration_10] already exists.\n",
      "tensor(-4., device='cuda:0')\n",
      "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -1.7098e-07, -4.7809e-01, -1.7098e-07,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(1.0000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "config.DCLSversion = 'v2'\n",
    "config.model_type = 'snn_delays_lr0'\n",
    "config.wandb_run_name = config.wandb_run_name.replace('(Pre-train)', '(Fine-tune_BIGLR_PLIF)')\n",
    "config.wandb_group_name = config.wandb_group_name.replace('(Pre-train)', '(Fine-tune)')\n",
    "\n",
    "config.lr_w = 1e-3\n",
    "config.max_lr_w = 2 * config.lr_w\n",
    "\n",
    "#config.dropout_p = 0.1\n",
    "#config.stateful_synapse_learnable = True\n",
    "#config.spiking_neuron_type = 'plif'\n",
    "config.epochs = 50\n",
    "\n",
    "train_loader, valid_loader = SHD_dataloaders(config)\n",
    "model_d = SnnDelays(config).to(device)\n",
    "\n",
    "\n",
    "model_d.load_state_dict(torch.load(PATH), strict=False)\n",
    "\n",
    "model_d.round_pos()\n",
    "\n",
    "w = model_d.blocks[0][0][0].weight\n",
    "p = model_d.blocks[0][0][0].P\n",
    "sig = model_d.blocks[0][0][0].SIG\n",
    "\n",
    "kernel = model_d.blocks[0][0][0].GCK.forward(w, p , sig)\n",
    "print(p[0,1,0,0])\n",
    "print(kernel[1,0])\n",
    "\n",
    "print(sig[0,0,0,0])\n",
    "\n",
    "model_d.train_model(train_loader, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7., device='cuda:0')\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -2.5519,  0.0000,  0.0000,  0.0000], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "w = model_d.blocks[0][0][0].weight\n",
    "p = model_d.blocks[0][0][0].P\n",
    "sig = model_d.blocks[0][0][0].SIG\n",
    "\n",
    "kernel = model_d.blocks[0][0][0].GCK.forward(w, p , sig)\n",
    "print(p[0,2,0,0])\n",
    "print(kernel[2,0])\n",
    "\n",
    "print(sig[0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn-delays",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
